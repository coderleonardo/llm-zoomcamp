{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama pull llama3.2\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "MODEL_HANDLE             = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "COLLECTION_NAME          = \"homework-rag-vector-search\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker pull qdrant/qdrant\n",
    "\n",
    "docker run -p 6333:6333 -p 6334:6334 \\\n",
    "   -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" \\\n",
    "   qdrant/qdrant\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I just discovered the course. Can I join now?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = TextEmbedding(\n",
    "    model_name=MODEL_HANDLE,\n",
    "    dimensionality=EMBEDDING_DIMENSIONALITY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_generator = embedding_model.embed([text])\n",
    "embeddings_list = list(embeddings_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.11726373885183883)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(embeddings_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Can I still join the course after the start date?\"\n",
    "\n",
    "embeddings_generator = embedding_model.embed([text, text2])\n",
    "embeddings_list = list(embeddings_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9008528895674548)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_list[0].dot(embeddings_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "documents = [\n",
    "  {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]\n",
    "\n",
    "texts = [doc['text'] for doc in documents]\n",
    "\n",
    "embeddings_generator = embedding_model.embed([query]+texts)\n",
    "embeddings_list = list(embeddings_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = [embeddings_list[0].dot(embeddings_list[i]) for i in range(1, len(embeddings_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.7629684696540238),\n",
       " np.float64(0.8182378150042889),\n",
       " np.float64(0.8085397398734189),\n",
       " np.float64(0.7133079015686243),\n",
       " np.float64(0.7304499234333598)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8514543236908068),\n",
       " np.float64(0.8436594159113068),\n",
       " np.float64(0.8408287048502558),\n",
       " np.float64(0.7755157969663908),\n",
       " np.float64(0.8086007795043938)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = [doc['question'] + ' ' + doc['text'] for doc in documents]\n",
    "\n",
    "embeddings_generator = embedding_model.embed([query]+full_text)\n",
    "embeddings_list = list(embeddings_generator)\n",
    "\n",
    "similarities = [embeddings_list[0].dot(embeddings_list[i]) for i in range(1, len(embeddings_list))]\n",
    "similarities # 0\n",
    "# the answer changed because we are using the full text now, with more information and closer to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(384)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min([model[\"dim\"] for model in TextEmbedding.list_supported_models()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-small-en\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/bge-small-en\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.13,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"BAAI/bge-small-en-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"qdrant/bge-small-en-v1.5-onnx-q\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.067,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"snowflake/snowflake-arctic-embed-xs\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"snowflake/snowflake-arctic-embed-xs\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"snowflake/snowflake-arctic-embed-s\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"snowflake/snowflake-arctic-embed-s\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.13,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"qdrant/all-MiniLM-L6-v2-onnx\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.22,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 384\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 384\n",
    "MODEL_HANDLE             = \"BAAI/bge-small-en\"\n",
    "COLLECTION_NAME          = \"homework-rag-vector-search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client = QdrantClient(\"http://localhost:6333\") # connecting to local Qdrant instance\n",
    "qd_client.delete_collection(collection_name=COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "\n",
    "for id, doc in enumerate(documents):\n",
    "    text = doc[\"question\"] + \" \" + doc[\"text\"]\n",
    "    vector = models.Document(text=text, model=MODEL_HANDLE)\n",
    "\n",
    "    point = models.PointStruct(\n",
    "        id=id,\n",
    "        vector=vector, # embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "qd_client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, \n",
    "                 course=\"mlops-zoomcamp\", \n",
    "                 limit=1):\n",
    "\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=MODEL_HANDLE\n",
    "        ),\n",
    "        # query_filter=models.Filter( # filter by course name\n",
    "        #     must=[\n",
    "        #         models.FieldCondition(\n",
    "        #             key=\"course\",\n",
    "        #             match=models.MatchValue(value=course)\n",
    "        #         )\n",
    "        #     ]\n",
    "        # ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True # to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return query_points\n",
    "    # results = []\n",
    "    \n",
    "    # for point in query_points.points:\n",
    "    #     results.append(point.payload)\n",
    "    \n",
    "    # return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=14, version=0, score=0.8703172, payload={'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.', 'section': 'General course-related questions', 'question': 'The course has already started. Can I still join it?', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search(\"I just discovered the course. Can I join now?\").points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
