{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama pull llama3.2\n",
    "import json\n",
    "\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "MODEL_HANDLE             = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "COLLECTION_NAME          = \"rag-vector-search\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker pull qdrant/qdrant\n",
    "\n",
    "docker run -p 6333:6333 -p 6334:6334 \\\n",
    "   -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" \\\n",
    "   qdrant/qdrant\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_document(document_path: str):\n",
    "    with open(document_path, \"r\") as f_in:\n",
    "        raw_documents = json.load(f_in)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for course_dict in raw_documents:\n",
    "        for doc in course_dict[\"documents\"]:\n",
    "            doc[\"course\"] = course_dict[\"course\"]\n",
    "            documents.append(doc)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'In this section of the course, the 5432 port of pgsql is mapped to your computer’s 5432 port. Which means you can access the postgres database via pgcli directly from your computer.\\nSo No, you don’t need to run it inside another container. Your local system will do.',\n",
       " 'section': 'Module 1: Docker and Terraform',\n",
       " 'question': 'PGCLI - INKhould we run pgcli inside another docker container?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = prepare_document(\"../01_introduction/documents.json\")\n",
    "\n",
    "documents[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "\n",
    "for id, doc in enumerate(documents):\n",
    "    text = doc[\"question\"] + \" \" + doc[\"text\"]\n",
    "    vector = models.Document(text=text, model=MODEL_HANDLE)\n",
    "\n",
    "    point = models.PointStruct(\n",
    "        id=id,\n",
    "        vector=vector, # embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "qd_client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\" # exact matching on string metadata fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, course=\"mlops-zoomcamp\", limit=5):\n",
    "\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=MODEL_HANDLE\n",
    "        ),\n",
    "        query_filter=models.Filter( # filter by course name\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True # to get metadata in the results\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(question, results):\n",
    "  \n",
    "  prompt_template = \"\"\"\n",
    "  you're a course teaching assistant. answer the QUESTION based on the context below. \n",
    "  use only the facts in the context to answer the question. \n",
    "  if you don't know the answer, say \"I don't know\".\n",
    "\n",
    "  QUESTION: {question}\n",
    "\n",
    "  CONTEXT: {context}\n",
    "  \"\"\"\n",
    "\n",
    "  context = \"\" \n",
    "\n",
    "  for doc in results:\n",
    "      context = context + f\"\\nsection: {doc['section']}\\n\" + \\\n",
    "          f\"question: {doc['question']}\\n\" + \\\n",
    "          f\"text: {doc['text']}\\n\\n\"\n",
    "  prompt = prompt_template.format(question=question, context=context).strip()\n",
    "\n",
    "  response: ChatResponse = chat(model=\"llama3.2\", messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt,\n",
    "    },\n",
    "  ])\n",
    "\n",
    "  return (response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(question: str, \n",
    "        num_results: int = 5, \n",
    "        course: str = \"data-engineering-zoomcamp\"\n",
    "        ) -> str:\n",
    "    # documents = prepare_document(\"documents.json\")\n",
    "    results = vector_search(question, course=course, limit=num_results)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        return \"I don't know\"\n",
    "\n",
    "    answer = llm(question, results)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"the course already started, can I still join?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'course': 'mlops-zoomcamp',\n",
      "  'question': 'What’s the difference between the 2023 and 2022 course?',\n",
      "  'section': '+-General course questions',\n",
      "  'text': 'The difference is the Orchestration and Monitoring modules. Those '\n",
      "          'videos will be re-recorded. The rest should mostly be the same.\\n'\n",
      "          'Also all of the homeworks will be changed for the 2023 cohort.'},\n",
      " {'course': 'mlops-zoomcamp',\n",
      "  'question': 'Is the AWS free tier enough for doing this course?',\n",
      "  'section': 'Module 1: Introduction',\n",
      "  'text': 'For many parts - yes. Some things like kinesis are not in AWS free '\n",
      "          'tier, but you can do it locally with localstack.'},\n",
      " {'course': 'mlops-zoomcamp',\n",
      "  'question': 'Will there be a 2024 Cohort? When will the 2024 cohort start?',\n",
      "  'section': '+-General course questions',\n",
      "  'text': 'Yes, it will start in May 2024'},\n",
      " {'course': 'mlops-zoomcamp',\n",
      "  'question': 'Are we free to choose our own topics for the final project?',\n",
      "  'section': '+-General course questions',\n",
      "  'text': 'Please pick up a problem you want to solve yourself. Potential '\n",
      "          'datasets can be found on either Kaggle, Hugging Face, Google, AWS, '\n",
      "          'or the UCI Machine Learning Datasets Repository.'},\n",
      " {'course': 'mlops-zoomcamp',\n",
      "  'question': 'What if my answer is not exactly the same as the choices '\n",
      "              'presented?',\n",
      "  'section': '+-General course questions',\n",
      "  'text': 'Please choose the closest one to your answer. Also do not post your '\n",
      "          'answer in the course slack channel.'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context, I\\'d say that yes, you can still join the course after the start date has passed. The text states: \"Yes, even if you don\\'t register, you\\'re still eligible to submit the homeworks.\" This implies that joining the course at any time is possible, as long as you complete the assignments and meet the project deadlines.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
